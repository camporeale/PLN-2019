{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sentiment.tass import InterTASSReader\n",
    "from sentiment.baselines import MostFrequent\n",
    "from sentiment.classifier import SentimentClassifier\n",
    "from sentiment.analysis import print_maxent_features, print_feature_weights_for_item\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2 -Mejoras al Clasificador Básico de Polaridad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>M-Precision</th>\n",
       "      <th>M-Recall</th>\n",
       "      <th>Macro-F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ES</td>\n",
       "      <td>basemf_base_es</td>\n",
       "      <td>baseline most frequent</td>\n",
       "      <td>43.28</td>\n",
       "      <td>85.82</td>\n",
       "      <td>25.00</td>\n",
       "      <td>38.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CR</td>\n",
       "      <td>basemf_base_cr</td>\n",
       "      <td>baseline most frequent</td>\n",
       "      <td>36.67</td>\n",
       "      <td>84.17</td>\n",
       "      <td>25.00</td>\n",
       "      <td>38.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PE</td>\n",
       "      <td>basemf_base_pe</td>\n",
       "      <td>baseline most frequent</td>\n",
       "      <td>47.60</td>\n",
       "      <td>86.90</td>\n",
       "      <td>25.00</td>\n",
       "      <td>38.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ES</td>\n",
       "      <td>maxent_base_es</td>\n",
       "      <td>baseline maxent</td>\n",
       "      <td>53.16</td>\n",
       "      <td>37.13</td>\n",
       "      <td>37.34</td>\n",
       "      <td>37.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CR</td>\n",
       "      <td>maxent_base_cr</td>\n",
       "      <td>baseline maxent</td>\n",
       "      <td>46.67</td>\n",
       "      <td>40.01</td>\n",
       "      <td>37.86</td>\n",
       "      <td>38.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PE</td>\n",
       "      <td>maxent_base_pe</td>\n",
       "      <td>baseline maxent</td>\n",
       "      <td>39.20</td>\n",
       "      <td>33.04</td>\n",
       "      <td>34.43</td>\n",
       "      <td>33.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ES</td>\n",
       "      <td>maxent_nltktok_es</td>\n",
       "      <td>maxent with nltk tokenizer</td>\n",
       "      <td>55.73</td>\n",
       "      <td>42.09</td>\n",
       "      <td>40.14</td>\n",
       "      <td>41.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CR</td>\n",
       "      <td>maxent_nltktok_cr</td>\n",
       "      <td>maxent with nltk tokenizer</td>\n",
       "      <td>52.67</td>\n",
       "      <td>43.22</td>\n",
       "      <td>43.01</td>\n",
       "      <td>43.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PE</td>\n",
       "      <td>maxent_nltktok_pe</td>\n",
       "      <td>maxent with nltk tokenizer</td>\n",
       "      <td>40.60</td>\n",
       "      <td>34.70</td>\n",
       "      <td>36.12</td>\n",
       "      <td>35.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ES</td>\n",
       "      <td>maxent_binary_es</td>\n",
       "      <td>maxent binary count</td>\n",
       "      <td>51.98</td>\n",
       "      <td>36.82</td>\n",
       "      <td>36.43</td>\n",
       "      <td>36.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CR</td>\n",
       "      <td>maxent_binary_cr</td>\n",
       "      <td>maxent binary count</td>\n",
       "      <td>48.00</td>\n",
       "      <td>39.84</td>\n",
       "      <td>38.89</td>\n",
       "      <td>39.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PE</td>\n",
       "      <td>maxent_binary_pe</td>\n",
       "      <td>maxent binary count</td>\n",
       "      <td>40.80</td>\n",
       "      <td>35.44</td>\n",
       "      <td>36.53</td>\n",
       "      <td>35.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ES</td>\n",
       "      <td>maxent_stop_es</td>\n",
       "      <td>maxent stop words</td>\n",
       "      <td>52.77</td>\n",
       "      <td>35.70</td>\n",
       "      <td>35.46</td>\n",
       "      <td>35.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CR</td>\n",
       "      <td>maxent_stop_cr</td>\n",
       "      <td>maxent stop words</td>\n",
       "      <td>47.33</td>\n",
       "      <td>45.67</td>\n",
       "      <td>36.97</td>\n",
       "      <td>40.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PE</td>\n",
       "      <td>maxent_stop_pe</td>\n",
       "      <td>maxent stop words</td>\n",
       "      <td>40.40</td>\n",
       "      <td>34.83</td>\n",
       "      <td>35.33</td>\n",
       "      <td>35.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ES</td>\n",
       "      <td>maxent_norm_es</td>\n",
       "      <td>maxent normalization</td>\n",
       "      <td>52.96</td>\n",
       "      <td>38.83</td>\n",
       "      <td>37.96</td>\n",
       "      <td>38.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CR</td>\n",
       "      <td>maxent_norm_cr</td>\n",
       "      <td>maxent normalization</td>\n",
       "      <td>47.33</td>\n",
       "      <td>38.64</td>\n",
       "      <td>38.19</td>\n",
       "      <td>38.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PE</td>\n",
       "      <td>maxent_norm_pe</td>\n",
       "      <td>maxent normalization</td>\n",
       "      <td>42.00</td>\n",
       "      <td>35.79</td>\n",
       "      <td>37.17</td>\n",
       "      <td>36.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ES</td>\n",
       "      <td>maxent_all_es</td>\n",
       "      <td>maxent nltk-binary-stop-norm</td>\n",
       "      <td>53.95</td>\n",
       "      <td>39.96</td>\n",
       "      <td>37.20</td>\n",
       "      <td>38.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CR</td>\n",
       "      <td>maxent_all_cr</td>\n",
       "      <td>maxent nltk-binary-stop-norm</td>\n",
       "      <td>48.67</td>\n",
       "      <td>41.51</td>\n",
       "      <td>38.21</td>\n",
       "      <td>39.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PE</td>\n",
       "      <td>maxent_all_pe</td>\n",
       "      <td>maxent nltk-binary-stop-norm</td>\n",
       "      <td>39.80</td>\n",
       "      <td>34.75</td>\n",
       "      <td>35.72</td>\n",
       "      <td>35.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Corpus         Classifier                       Comment  Accuracy  \\\n",
       "0      ES     basemf_base_es        baseline most frequent     43.28   \n",
       "1      CR     basemf_base_cr        baseline most frequent     36.67   \n",
       "2      PE     basemf_base_pe        baseline most frequent     47.60   \n",
       "3      ES     maxent_base_es               baseline maxent     53.16   \n",
       "4      CR     maxent_base_cr               baseline maxent     46.67   \n",
       "5      PE     maxent_base_pe               baseline maxent     39.20   \n",
       "6      ES  maxent_nltktok_es    maxent with nltk tokenizer     55.73   \n",
       "7      CR  maxent_nltktok_cr    maxent with nltk tokenizer     52.67   \n",
       "8      PE  maxent_nltktok_pe    maxent with nltk tokenizer     40.60   \n",
       "9      ES   maxent_binary_es           maxent binary count     51.98   \n",
       "10     CR   maxent_binary_cr           maxent binary count     48.00   \n",
       "11     PE   maxent_binary_pe           maxent binary count     40.80   \n",
       "12     ES     maxent_stop_es             maxent stop words     52.77   \n",
       "13     CR     maxent_stop_cr             maxent stop words     47.33   \n",
       "14     PE     maxent_stop_pe             maxent stop words     40.40   \n",
       "15     ES     maxent_norm_es          maxent normalization     52.96   \n",
       "16     CR     maxent_norm_cr          maxent normalization     47.33   \n",
       "17     PE     maxent_norm_pe          maxent normalization     42.00   \n",
       "18     ES      maxent_all_es  maxent nltk-binary-stop-norm     53.95   \n",
       "19     CR      maxent_all_cr  maxent nltk-binary-stop-norm     48.67   \n",
       "20     PE      maxent_all_pe  maxent nltk-binary-stop-norm     39.80   \n",
       "\n",
       "    M-Precision  M-Recall  Macro-F1  \n",
       "0         85.82     25.00     38.72  \n",
       "1         84.17     25.00     38.55  \n",
       "2         86.90     25.00     38.83  \n",
       "3         37.13     37.34     37.23  \n",
       "4         40.01     37.86     38.91  \n",
       "5         33.04     34.43     33.72  \n",
       "6         42.09     40.14     41.09  \n",
       "7         43.22     43.01     43.11  \n",
       "8         34.70     36.12     35.40  \n",
       "9         36.82     36.43     36.63  \n",
       "10        39.84     38.89     39.36  \n",
       "11        35.44     36.53     35.98  \n",
       "12        35.70     35.46     35.58  \n",
       "13        45.67     36.97     40.86  \n",
       "14        34.83     35.33     35.08  \n",
       "15        38.83     37.96     38.39  \n",
       "16        38.64     38.19     38.41  \n",
       "17        35.79     37.17     36.47  \n",
       "18        39.96     37.20     38.53  \n",
       "19        41.51     38.21     39.79  \n",
       "20        34.75     35.72     35.23  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"Corpus\",\"Classifier\",\"Comment\",\"Accuracy\",\"M-Precision\",\"M-Recall\",\"Macro-F1\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3 - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Training Set\n",
    "corpus_train = \"./InterTASS/ES/intertass-ES-train-tagged.xml\"\n",
    "reader_train = InterTASSReader(corpus_train)\n",
    "X_train, y_train = list(reader_train.X()), list(reader_train.y())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Dev Set\n",
    "corpus_dev = \"./InterTASS/ES/intertass-ES-development-tagged.xml\"\n",
    "reader_dev = InterTASSReader(corpus_dev)\n",
    "X_dev, y_dev = list(reader_dev.X()), list(reader_dev.y())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, X, y_true):\n",
    "    y_pred = model.predict(X)\n",
    "    acc = metrics.accuracy_score(y_true, y_pred)\n",
    "    f1 = metrics.f1_score(y_true, y_pred, average='macro')\n",
    "    return {'acc': acc, 'f1': f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "\n",
    "pipeline_lr = Pipeline([\n",
    "            ('vect', CountVectorizer(tokenizer=word_tokenize)),\n",
    "            ('clf', clf),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'clf__penalty': ('l1','l2'),\n",
    "    'clf__C': [0.001, 0.01, 0.1, 1, 10],\n",
    "}\n",
    "\n",
    "params_list = list(ParameterGrid(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/camporeale/miniconda3/envs/pln2019/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/camporeale/miniconda3/envs/pln2019/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/camporeale/miniconda3/envs/pln2019/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for params in params_list:\n",
    "    pipeline_lr.set_params(**params)\n",
    "    pipeline_lr.fit(X_train, y_train)\n",
    "    result = eval(pipeline_lr, X_dev, y_dev)\n",
    "\n",
    "    results.append({\n",
    "        **result,\n",
    "        **params,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>clf__C</th>\n",
       "      <th>clf__penalty</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.559289</td>\n",
       "      <td>0.100</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.350232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.557312</td>\n",
       "      <td>1.000</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.391317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.537549</td>\n",
       "      <td>10.000</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.384407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.535573</td>\n",
       "      <td>1.000</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.376214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.529644</td>\n",
       "      <td>0.010</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.287032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.527668</td>\n",
       "      <td>0.100</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.293593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.521739</td>\n",
       "      <td>10.000</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.383559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.476285</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.223608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.436759</td>\n",
       "      <td>0.010</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.157781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.432806</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.151034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc  clf__C clf__penalty        f1\n",
       "5  0.559289   0.100           l2  0.350232\n",
       "7  0.557312   1.000           l2  0.391317\n",
       "9  0.537549  10.000           l2  0.384407\n",
       "6  0.535573   1.000           l1  0.376214\n",
       "3  0.529644   0.010           l2  0.287032\n",
       "4  0.527668   0.100           l1  0.293593\n",
       "8  0.521739  10.000           l1  0.383559\n",
       "1  0.476285   0.001           l2  0.223608\n",
       "2  0.436759   0.010           l1  0.157781\n",
       "0  0.432806   0.001           l1  0.151034"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.sort_values(['acc', 'f1'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC()\n",
    "\n",
    "pipeline_svm = Pipeline([\n",
    "            ('vect', CountVectorizer(tokenizer=word_tokenize)),\n",
    "            ('clf', clf),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'clf__penalty': ['l1','l2'],\n",
    "    'clf__C': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'clf__dual': [False] \n",
    "}\n",
    "\n",
    "params_list = list(ParameterGrid(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/camporeale/miniconda3/envs/pln2019/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for params in params_list:\n",
    "    pipeline_svm.set_params(**params)\n",
    "    pipeline_svm.fit(X_train, y_train)\n",
    "    result = eval(pipeline_svm, X_dev, y_dev)\n",
    "\n",
    "    results.append({\n",
    "        **result,\n",
    "        **params,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>clf__C</th>\n",
       "      <th>clf__dual</th>\n",
       "      <th>clf__penalty</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.567194</td>\n",
       "      <td>0.010</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.348590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.561265</td>\n",
       "      <td>0.100</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.409613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.100</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.329601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.531621</td>\n",
       "      <td>1.000</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.400324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.527668</td>\n",
       "      <td>0.001</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.284634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.525692</td>\n",
       "      <td>10.000</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.392753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.515810</td>\n",
       "      <td>10.000</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.397132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.511858</td>\n",
       "      <td>0.010</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.266006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.509881</td>\n",
       "      <td>1.000</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.372984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.432806</td>\n",
       "      <td>0.001</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.151034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc  clf__C  clf__dual clf__penalty        f1\n",
       "3  0.567194   0.010      False           l2  0.348590\n",
       "5  0.561265   0.100      False           l2  0.409613\n",
       "4  0.545455   0.100      False           l1  0.329601\n",
       "7  0.531621   1.000      False           l2  0.400324\n",
       "1  0.527668   0.001      False           l2  0.284634\n",
       "8  0.525692  10.000      False           l1  0.392753\n",
       "9  0.515810  10.000      False           l2  0.397132\n",
       "2  0.511858   0.010      False           l1  0.266006\n",
       "6  0.509881   1.000      False           l1  0.372984\n",
       "0  0.432806   0.001      False           l1  0.151034"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.sort_values(['acc', 'f1'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "\n",
    "pipeline_nb = Pipeline([\n",
    "            ('vect', CountVectorizer(tokenizer=word_tokenize)),\n",
    "            ('clf', clf),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'clf__alpha': [1, 0.1, 0.01, 0.0001] \n",
    "}\n",
    "\n",
    "params_list = list(ParameterGrid(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/camporeale/miniconda3/envs/pln2019/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for params in params_list:\n",
    "    pipeline_nb.set_params(**params)\n",
    "    pipeline_nb.fit(X_train, y_train)\n",
    "    result = eval(pipeline_nb, X_dev, y_dev)\n",
    "\n",
    "    results.append({\n",
    "        **result,\n",
    "        **params,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>clf__alpha</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.565217</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.316191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.549407</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.399606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.523715</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.393394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.507905</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.374724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc  clf__alpha        f1\n",
       "0  0.565217      1.0000  0.316191\n",
       "1  0.549407      0.1000  0.399606\n",
       "2  0.523715      0.0100  0.393394\n",
       "3  0.507905      0.0001  0.374724"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.sort_values(['acc', 'f1'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4 - Inspección de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "          dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "          lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "          ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "          strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "          tokenizer=<function word_tokenize at 0x7f78d1b14d90>,\n",
       "          vocabulary=None)),\n",
       " ('clf',\n",
       "  LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "            n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "            tol=0.0001, verbose=0, warm_start=False))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_lr.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = pipeline_lr.named_steps['vect']\n",
    "clf = pipeline_lr.named_steps['clf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5049"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = vect.get_feature_names()\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N:\n",
      "\tbonito buen guapa encuentre 11:11 irresponsable buena genial algunos voy ([-2.86934595 -2.08702273 -2.08389864 -1.91690854 -1.91690854 -1.85684378\n",
      " -1.74317015 -1.69395729 -1.66076886 -1.65224562])\n",
      "\tpoco sola cosa pobre mismo odio ni feo peor triste ([1.91680946 1.93080402 2.08830209 2.10199825 2.11868748 2.17602953\n",
      " 2.48799712 2.5166921  2.71250342 3.05123425])\n",
      "NEU:\n",
      "\tgracias su peor hoy triste ana feo sola ? cosas ([-1.65716948 -1.65133671 -1.6333469  -1.43883509 -1.41755725 -1.32158237\n",
      " -1.30704899 -1.26248005 -1.26182554 -1.20775355])\n",
      "\tpelado slammactivao encuentre 11:11 imdariusb1tches ineternete crtkftauryn plan nerviosa viejas ([1.86288855 1.86288855 2.04737787 2.04737787 2.11642018 2.11735041\n",
      " 2.16748105 2.19855978 2.75534623 3.1164695 ])\n",
      "NONE:\n",
      "\tmal buen ser nada serio feliz están más siempre sin ([-1.71397182 -1.46810325 -1.35430631 -1.34377599 -1.26008118 -1.24795138\n",
      " -1.22523022 -1.20268792 -1.20204557 -1.18798703])\n",
      "\tfecha ichuso empezado indirecta abstracto caspitoo semana distraído yaaa clrealy ([1.96480354 2.06507208 2.06507208 2.21578194 2.24644246 2.24644246\n",
      " 2.24672834 2.38573999 2.39961975 2.42272549])\n",
      "P:\n",
      "\ttriste ni plan largo horas alguien echo o mundo pobre ([-1.82989369 -1.81610547 -1.53571894 -1.50091463 -1.43708341 -1.37710547\n",
      " -1.36407942 -1.36005982 -1.34085269 -1.31653097])\n",
      "\tbuenos mejor enfadada genial feliz irresponsable cariñoso bonito buen guapa ([2.24409917 2.25132995 2.29002863 2.33219213 2.38803357 2.76703561\n",
      " 2.87307595 3.23337677 3.4017249  3.4044288 ])\n"
     ]
    }
   ],
   "source": [
    "print_maxent_features(vect, clf, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5 - Análisis de Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline_lr.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos probabilidades \n",
    "y_proba = pipeline_lr.predict_proba(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un dataframe con los tweets mal clasificados, ordenados por los que tuvieron probabilidad más alta sobre \n",
    "# clase errónea (aquellos sobre los que el clasificador tenía más seguridad en su predicción)\n",
    "errors = []\n",
    "probs = {\"N\":0,\"NEU\":1,\"NONE\":2,\"P\":3}\n",
    "\n",
    "for i,(x, y1, y2, proba) in enumerate(zip(X_dev, y_dev, y_pred, y_proba )):\n",
    "    if y1 != y2:\n",
    "        diff = proba\n",
    "        errors.append({\n",
    "            'index':i,\n",
    "            'item': x,\n",
    "            'true': y1,\n",
    "            'pred': y2,\n",
    "            'prob_pred': proba[probs[y2]],\n",
    "            })\n",
    "\n",
    "errdf = pd.DataFrame(errors,columns=['index','item','true','pred','prob_pred'])\n",
    "errdf.sort_values('prob_pred', inplace=True,ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>item</th>\n",
       "      <th>true</th>\n",
       "      <th>pred</th>\n",
       "      <th>prob_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>416</td>\n",
       "      <td>URGENTE!!! VENTA MY NAME TIKETS!!!\\nTengo dos ...</td>\n",
       "      <td>NONE</td>\n",
       "      <td>P</td>\n",
       "      <td>0.998672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>137</td>\n",
       "      <td>@LaQueSoySiempre @ealbaga Por desgracia vende ...</td>\n",
       "      <td>N</td>\n",
       "      <td>P</td>\n",
       "      <td>0.991105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>213</td>\n",
       "      <td>me he ido a la ducha y se me ha olvidado coger...</td>\n",
       "      <td>NONE</td>\n",
       "      <td>N</td>\n",
       "      <td>0.987353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>270</td>\n",
       "      <td>@MV3ga hay cosas del hilo con las que discrepo...</td>\n",
       "      <td>NONE</td>\n",
       "      <td>N</td>\n",
       "      <td>0.984325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>291</td>\n",
       "      <td>@AnaSJuarez @OfficialMauiJim ¡Hola Ana! Te hem...</td>\n",
       "      <td>NONE</td>\n",
       "      <td>P</td>\n",
       "      <td>0.982290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>223</td>\n",
       "      <td>Cuando no puedo dormir, escribo todo lo que pr...</td>\n",
       "      <td>P</td>\n",
       "      <td>N</td>\n",
       "      <td>0.981207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>428</td>\n",
       "      <td>Yo estaba cansadete, pero de repente me habla ...</td>\n",
       "      <td>P</td>\n",
       "      <td>N</td>\n",
       "      <td>0.977272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>153</td>\n",
       "      <td>15. No me gusta el término  \\n16. Meh \\n17. De...</td>\n",
       "      <td>NONE</td>\n",
       "      <td>N</td>\n",
       "      <td>0.972211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>250</td>\n",
       "      <td>@UniversoMujer18 ya se acabo la hora jajaja es...</td>\n",
       "      <td>P</td>\n",
       "      <td>N</td>\n",
       "      <td>0.956387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>320</td>\n",
       "      <td>A mí nunca me podrán hacer una broma porque no...</td>\n",
       "      <td>NONE</td>\n",
       "      <td>N</td>\n",
       "      <td>0.955317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>284</td>\n",
       "      <td>Ea ya mañana cuando me despierte empieza la fi...</td>\n",
       "      <td>P</td>\n",
       "      <td>N</td>\n",
       "      <td>0.949240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>222</td>\n",
       "      <td>¡Ya hemos contactado con los ganadores de #Yos...</td>\n",
       "      <td>NONE</td>\n",
       "      <td>P</td>\n",
       "      <td>0.944914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18</td>\n",
       "      <td>Hola buenos días, me he dormido a las 5 y algo...</td>\n",
       "      <td>P</td>\n",
       "      <td>N</td>\n",
       "      <td>0.942384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>395</td>\n",
       "      <td>#astroymas lo necesito. Se me acaba de romper ...</td>\n",
       "      <td>N</td>\n",
       "      <td>P</td>\n",
       "      <td>0.938942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>217</td>\n",
       "      <td>@LovNaty Tu vida ha parido a un grandisimo hij...</td>\n",
       "      <td>N</td>\n",
       "      <td>P</td>\n",
       "      <td>0.938682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>439</td>\n",
       "      <td>Tengo dos horas seguidas de latín y griego.\\n\\...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>N</td>\n",
       "      <td>0.930661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>438</td>\n",
       "      <td>@MoratoX_ genial, pero ten cuidado está muy vi...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>P</td>\n",
       "      <td>0.930044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14</td>\n",
       "      <td>@SoofRawr + ni el de al lado, la \"manita\" que ...</td>\n",
       "      <td>NONE</td>\n",
       "      <td>N</td>\n",
       "      <td>0.927612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>396</td>\n",
       "      <td>Bueno, pues vamos a recuperar el tiempo perdid...</td>\n",
       "      <td>P</td>\n",
       "      <td>N</td>\n",
       "      <td>0.922894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>196</td>\n",
       "      <td>Un poquito de Ministerio del Tiempo y a dormir...</td>\n",
       "      <td>P</td>\n",
       "      <td>N</td>\n",
       "      <td>0.921488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                               item  true pred  \\\n",
       "198    416  URGENTE!!! VENTA MY NAME TIKETS!!!\\nTengo dos ...  NONE    P   \n",
       "67     137  @LaQueSoySiempre @ealbaga Por desgracia vende ...     N    P   \n",
       "107    213  me he ido a la ducha y se me ha olvidado coger...  NONE    N   \n",
       "129    270  @MV3ga hay cosas del hilo con las que discrepo...  NONE    N   \n",
       "143    291  @AnaSJuarez @OfficialMauiJim ¡Hola Ana! Te hem...  NONE    P   \n",
       "111    223  Cuando no puedo dormir, escribo todo lo que pr...     P    N   \n",
       "202    428  Yo estaba cansadete, pero de repente me habla ...     P    N   \n",
       "74     153  15. No me gusta el término  \\n16. Meh \\n17. De...  NONE    N   \n",
       "119    250  @UniversoMujer18 ya se acabo la hora jajaja es...     P    N   \n",
       "156    320  A mí nunca me podrán hacer una broma porque no...  NONE    N   \n",
       "138    284  Ea ya mañana cuando me despierte empieza la fi...     P    N   \n",
       "110    222  ¡Ya hemos contactado con los ganadores de #Yos...  NONE    P   \n",
       "13      18  Hola buenos días, me he dormido a las 5 y algo...     P    N   \n",
       "191    395  #astroymas lo necesito. Se me acaba de romper ...     N    P   \n",
       "108    217  @LovNaty Tu vida ha parido a un grandisimo hij...     N    P   \n",
       "206    439  Tengo dos horas seguidas de latín y griego.\\n\\...   NEU    N   \n",
       "205    438  @MoratoX_ genial, pero ten cuidado está muy vi...   NEU    P   \n",
       "10      14  @SoofRawr + ni el de al lado, la \"manita\" que ...  NONE    N   \n",
       "192    396  Bueno, pues vamos a recuperar el tiempo perdid...     P    N   \n",
       "98     196  Un poquito de Ministerio del Tiempo y a dormir...     P    N   \n",
       "\n",
       "     prob_pred  \n",
       "198   0.998672  \n",
       "67    0.991105  \n",
       "107   0.987353  \n",
       "129   0.984325  \n",
       "143   0.982290  \n",
       "111   0.981207  \n",
       "202   0.977272  \n",
       "74    0.972211  \n",
       "119   0.956387  \n",
       "156   0.955317  \n",
       "138   0.949240  \n",
       "110   0.944914  \n",
       "13    0.942384  \n",
       "191   0.938942  \n",
       "108   0.938682  \n",
       "206   0.930661  \n",
       "205   0.930044  \n",
       "10    0.927612  \n",
       "192   0.922894  \n",
       "98    0.921488  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errdf[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = errdf['index'][0:10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['URGENTE!!! VENTA MY NAME TIKETS!!!\\nTengo dos tickets ULTIMATE VIP pero no podemos ir  los vendo más baratos, contactad conmigo!!!',\n",
       " '@LaQueSoySiempre @ealbaga Por desgracia vende más  ,riñas,trifulcas,peleas,al cuello!! mátalo!!',\n",
       " 'me he ido a la ducha y se me ha olvidado coger la ropa  ahors tengo que salir a por ella y como haya alguien en mi ventana me ve desnuda',\n",
       " '@MV3ga hay cosas del hilo con las que discrepo. Como me sigues hace poco, te aviso de que yo hago rt a lo interesante, coincida o no ',\n",
       " '@AnaSJuarez @OfficialMauiJim ¡Hola Ana! Te hemos contestado por mensaje privado, donde no hay limitación de caracteres  ¡Gracias!',\n",
       " 'Cuando no puedo dormir, escribo todo lo que preocupa en una libreta que alguien me regaló y es como un somnífero instantáneo ',\n",
       " 'Yo estaba cansadete, pero de repente me habla a un amigo para jugar un ratejo a la Beta de Battlefield 1, y quién le dice que no al chico ',\n",
       " '15. No me gusta el término  \\n16. Meh \\n17. Depende de qué\\n18. No \\n19 Un perrete prechiocho \\n20. No\\n21. No\\n22. El año pasado',\n",
       " '@UniversoMujer18 ya se acabo la hora jajaja estoy expectante a ver si me ha tocado el #cubreSelFem para llevarlo a todos lados puesto ',\n",
       " 'A mí nunca me podrán hacer una broma porque no cojo llamadas y menos cuando son ocultas ']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[X_dev[index] for index in errors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = \"@LaQueSoySiempre @ealbaga Por desgracia vende más  ,riñas,trifulcas,peleas,al cuello!! mátalo!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "! [-1.00453974 -0.95153362 -0.19846824  1.36069119]\n",
      ", [-0.3870915  -0.07526614 -0.39497008  0.50956257]\n",
      "@ [-0.37599216 -0.21543827  0.2713075   0.06814566]\n",
      "al [ 0.51110109 -0.39551092  0.05058118 -0.4960745 ]\n",
      "desgracia [ 0.61744223 -0.21158639 -0.09616715 -0.21244867]\n",
      "más [-0.52540095  1.27775123 -1.20268792  0.18649803]\n",
      "por [-0.54276769  0.50699498 -0.44647751  0.31744384]\n",
      "vende [ 0.38222646 -0.44397838  0.48114509 -0.38853147]\n"
     ]
    }
   ],
   "source": [
    "# Features que intervienen en la clasificación\n",
    "print_feature_weights_for_item(vect,clf,tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['P'], dtype='<U4')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicción del tweet original menos los signos de exclamación\n",
    "pipeline_lr.predict([tweet.replace(\"!\",\"\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['P'], dtype='<U4')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reemplazamos comas por espacios\n",
    "pipeline_lr.predict([tweet.replace(\",\",\" \")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['N'], dtype='<U4')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quitamos tanto comas como signos de exclamanación\n",
    "pipeline_lr.predict([tweet.replace(\"!\",\"\").replace(\",\",\" \")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@ [-0.37599216 -0.21543827  0.2713075   0.06814566]\n",
      "desgracia [ 0.61744223 -0.21158639 -0.09616715 -0.21244867]\n",
      "más [-0.52540095  1.27775123 -1.20268792  0.18649803]\n",
      "por [-0.54276769  0.50699498 -0.44647751  0.31744384]\n",
      "vende [ 0.38222646 -0.44397838  0.48114509 -0.38853147]\n"
     ]
    }
   ],
   "source": [
    "print_feature_weights_for_item(vect,clf,tweet.replace(\"!\",\"\").replace(\",\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalmente obtuvimos el resultado esperado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@noseashetero 1000/10 de verdad a ti que voy a decir petarda que te quiero más que a mí mismo  ✨'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a ver que sucede si eliminamos comas y signos de exclamación\n",
    "X_train_p = [x.replace(\"!\",\"\").replace(\",\",\" \") for x in X_train]\n",
    "X_dev_p = [x.replace(\"!\",\"\").replace(\",\",\" \") for x in X_dev]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'clf__penalty': ('l1','l2'),\n",
    "    'clf__C': [0.001, 0.01, 0.1, 1, 10],\n",
    "}\n",
    "\n",
    "params_list = list(ParameterGrid(param_grid))\n",
    "results = []\n",
    "for params in params_list:\n",
    "    pipeline_lr.set_params(**params)\n",
    "    pipeline_lr.fit(X_train_p, y_train)\n",
    "    result = eval(pipeline_lr, X_dev_p, y_dev)\n",
    "\n",
    "    results.append({\n",
    "        **result,\n",
    "        **params,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>clf__C</th>\n",
       "      <th>clf__penalty</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.543478</td>\n",
       "      <td>1.000</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.381997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.539526</td>\n",
       "      <td>0.100</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.347457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.529644</td>\n",
       "      <td>10.000</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.386022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.509881</td>\n",
       "      <td>1.000</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.358392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.505929</td>\n",
       "      <td>10.000</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.379470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.505929</td>\n",
       "      <td>0.010</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.271386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.476285</td>\n",
       "      <td>0.100</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.263753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.436759</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.160554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.436759</td>\n",
       "      <td>0.010</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.157781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.432806</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.151034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc  clf__C clf__penalty        f1\n",
       "7  0.543478   1.000           l2  0.381997\n",
       "5  0.539526   0.100           l2  0.347457\n",
       "9  0.529644  10.000           l2  0.386022\n",
       "6  0.509881   1.000           l1  0.358392\n",
       "8  0.505929  10.000           l1  0.379470\n",
       "3  0.505929   0.010           l2  0.271386\n",
       "4  0.476285   0.100           l1  0.263753\n",
       "1  0.436759   0.001           l2  0.160554\n",
       "2  0.436759   0.010           l1  0.157781\n",
       "0  0.432806   0.001           l1  0.151034"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.sort_values(['acc', 'f1'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados son ligeramente peores, por lo que estimamos que el signo de exclamación y la coma juegan algún rol"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
